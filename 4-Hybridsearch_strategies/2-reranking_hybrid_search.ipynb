{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0effdd26",
   "metadata": {},
   "source": [
    "# Reranking Hybrid Search Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a4d666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Desktop\\RAGUdemy\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf061a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=TextLoader(\"langchain_intr.txt\",encoding=\"utf-8\")\n",
    "raw_docs=loader.load()\n",
    "# split documents into chunks\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=300,chunk_overlap=30)\n",
    "chunks=splitter.split_documents(raw_docs)\n",
    "\n",
    "# embedding model\n",
    "embedding_model=OpenAIEmbeddings()\n",
    "vectorstore=FAISS.from_documents(chunks,embedding_model)\n",
    "# Retriever\n",
    "retriever_openai=vectorstore.as_retriever(search_kwargs={\"k\":5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42f82f",
   "metadata": {},
   "source": [
    "### Reranking\n",
    "- step-1 prompt\n",
    "- step-2 llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02b90a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000244330E2FD0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000244330E2C40>, root_client=<openai.OpenAI object at 0x00000244330E0FC0>, root_async_client=<openai.AsyncOpenAI object at 0x00000244330E2EA0>, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt for reranking\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm=init_chat_model(\"openai:gpt-3.5-turbo\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e21f364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_prompt=PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a helpful assistant. Your task is to rank the following documents from most to least relevant to the user's question.\n",
    "\n",
    "User Question: \"{question}\"\n",
    "\n",
    "Documents:\n",
    "{documents}\n",
    "\n",
    "Instructions:\n",
    "- Think about the relevance of each document to the user's question.\n",
    "- Return a list of document indices in ranked order, starting from the most relevant.\n",
    "\n",
    "Output format: comma-separated document indices (e.g., 2,1,3,0,...)\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbd008c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9994eadf-8e4b-4aeb-93ab-785c1145d32a', metadata={'source': 'langchain_intr.txt'}, page_content='Memory in LangChain enables context retention across multiple steps in a conversation or task, making the application more coherent and stateful.'),\n",
       " Document(id='9c2ee13d-7cda-4c3a-ad36-74098bd7be31', metadata={'source': 'langchain_intr.txt'}, page_content='LangChain is a flexible framework designed for developing applications powered by large language models (LLMs). It provides tools and abstractions to work with LLMs more effectively and includes components for prompt management, chains, memory, and agents.'),\n",
       " Document(id='5d61d68c-b408-4ca7-aa17-9eb6dc89d55b', metadata={'source': 'langchain_intr.txt'}, page_content='Agents in LangChain are chains that use LLMs to decide which tools to use and in what order. This makes them suitable for multi-step tasks like question answering with search and code execution.'),\n",
       " Document(id='93eabe8e-8381-44b9-ba4b-b2130c0abce9', metadata={'source': 'langchain_intr.txt'}, page_content='LangChain supports tool integration including web search, calculators, and APIs, allowing LLMs to interact with external systems and respond more accurately to dynamic queries.'),\n",
       " Document(id='f07fed7f-12ba-4ba0-bcb6-75d7606045a7', metadata={'source': 'langchain_intr.txt'}, page_content='LangChain integrates with many third-party services such as OpenAI, Hugging Face, and Cohere. This enables developers to experiment with different models and optimize performance for specific use cases like summarization, question answering, or translation.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"How can i use langchain to build an application with memory and tools?\"\n",
    "retrieved_docs=retriever_openai.invoke(query)\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "439d063e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['documents', 'question'], input_types={}, partial_variables={}, template='\\n    You are a helpful assistant. Your task is to rank the following documents from most to least relevant to the user\\'s question.\\n\\nUser Question: \"{question}\"\\n\\nDocuments:\\n{documents}\\n\\nInstructions:\\n- Think about the relevance of each document to the user\\'s question.\\n- Return a list of document indices in ranked order, starting from the most relevant.\\n\\nOutput format: comma-separated document indices (e.g., 2,1,3,0,...)\\n    ')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000244330E2FD0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000244330E2C40>, root_client=<openai.OpenAI object at 0x00000244330E0FC0>, root_async_client=<openai.AsyncOpenAI object at 0x00000244330E2EA0>, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=rerank_prompt|llm|StrOutputParser()\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d82c156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.Memory in LangChain enables context retention across multiple steps in a conversation or task, making the application more coherent and stateful.\\n 2.LangChain is a flexible framework designed for developing applications powered by large language models (LLMs). It provides tools and abstractions to work with LLMs more effectively and includes components for prompt management, chains, memory, and agents.\\n 3.Agents in LangChain are chains that use LLMs to decide which tools to use and in what order. This makes them suitable for multi-step tasks like question answering with search and code execution.\\n 4.LangChain supports tool integration including web search, calculators, and APIs, allowing LLMs to interact with external systems and respond more accurately to dynamic queries.\\n 5.LangChain integrates with many third-party services such as OpenAI, Hugging Face, and Cohere. This enables developers to experiment with different models and optimize performance for specific use cases like summarization, question answering, or translation.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_lines=[f\"{i+1}.{doc.page_content}\" for i,doc in enumerate(retrieved_docs)]\n",
    "formatted_docs=\"\\n \".join(doc_lines)\n",
    "formatted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d36415a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2,1,3,4,5'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"How can i use langchain to build an application with memory and tools?\"\n",
    "rerank=chain.invoke({\"question\":query,\"documents\":formatted_docs})\n",
    "rerank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0e8ead0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9c2ee13d-7cda-4c3a-ad36-74098bd7be31', metadata={'source': 'langchain_intr.txt'}, page_content='LangChain is a flexible framework designed for developing applications powered by large language models (LLMs). It provides tools and abstractions to work with LLMs more effectively and includes components for prompt management, chains, memory, and agents.'),\n",
       " Document(id='9994eadf-8e4b-4aeb-93ab-785c1145d32a', metadata={'source': 'langchain_intr.txt'}, page_content='Memory in LangChain enables context retention across multiple steps in a conversation or task, making the application more coherent and stateful.'),\n",
       " Document(id='5d61d68c-b408-4ca7-aa17-9eb6dc89d55b', metadata={'source': 'langchain_intr.txt'}, page_content='Agents in LangChain are chains that use LLMs to decide which tools to use and in what order. This makes them suitable for multi-step tasks like question answering with search and code execution.'),\n",
       " Document(id='93eabe8e-8381-44b9-ba4b-b2130c0abce9', metadata={'source': 'langchain_intr.txt'}, page_content='LangChain supports tool integration including web search, calculators, and APIs, allowing LLMs to interact with external systems and respond more accurately to dynamic queries.'),\n",
       " Document(id='f07fed7f-12ba-4ba0-bcb6-75d7606045a7', metadata={'source': 'langchain_intr.txt'}, page_content='LangChain integrates with many third-party services such as OpenAI, Hugging Face, and Cohere. This enables developers to experiment with different models and optimize performance for specific use cases like summarization, question answering, or translation.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes=rerank.split(\",\")\n",
    "rerank_docs=[retrieved_docs[int(i)-1] for i in indexes]\n",
    "rerank_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93d3aac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rank1:\n",
      "LangChain is a flexible framework designed for developing applications powered by large language models (LLMs). It provides tools and abstractions to work with LLMs more effectively and includes components for prompt management, chains, memory, and agents.\n",
      "\n",
      "Rank2:\n",
      "Memory in LangChain enables context retention across multiple steps in a conversation or task, making the application more coherent and stateful.\n",
      "\n",
      "Rank3:\n",
      "Agents in LangChain are chains that use LLMs to decide which tools to use and in what order. This makes them suitable for multi-step tasks like question answering with search and code execution.\n",
      "\n",
      "Rank4:\n",
      "LangChain supports tool integration including web search, calculators, and APIs, allowing LLMs to interact with external systems and respond more accurately to dynamic queries.\n",
      "\n",
      "Rank5:\n",
      "LangChain integrates with many third-party services such as OpenAI, Hugging Face, and Cohere. This enables developers to experiment with different models and optimize performance for specific use cases like summarization, question answering, or translation.\n"
     ]
    }
   ],
   "source": [
    "# Print result\n",
    "for i,doc in enumerate(rerank_docs):\n",
    "    print(f\"\\nRank{i+1}:\\n{doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a8421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
