{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d7ab9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634b606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sample documents\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain helps build LLM applications.\"),\n",
    "    Document(page_content=\"Pinecone is a vector database for semantic search.\"),\n",
    "    Document(page_content=\"The Eiffel Tower is located in Paris.\"),\n",
    "    Document(page_content=\"Langchain can be used to develop agentic ai application.\"),\n",
    "    Document(page_content=\"Langchain has many types of retrievers.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff3fcc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding creation\n",
    "embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "dense_vectorstore=FAISS.from_documents(docs,embedding)\n",
    "dense_retriever=dense_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d866e057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002251FF59310>, search_kwargs={}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x000002251FF5B9D0>, k=3)], weights=[0.7, 0.3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_retriever=BM25Retriever.from_documents(docs)\n",
    "sparse_retriever.k=3\n",
    "hybrid_retriever=EnsembleRetriever(\n",
    "    retrievers=[dense_retriever,sparse_retriever],\n",
    "    weights=[0.7,0.3])\n",
    "hybrid_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93a63d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc1:\n",
      "LangChain helps build LLM applications.\n",
      "doc2:\n",
      "Langchain can be used to develop agentic ai application.\n",
      "doc3:\n",
      "Langchain has many types of retrievers.\n",
      "doc4:\n",
      "Pinecone is a vector database for semantic search.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Query and get results\n",
    "query = \"How can I build an application using LLMs?\"\n",
    "results=hybrid_retriever.invoke(query)\n",
    "for i,doc in enumerate(results):\n",
    "    print(f\"doc{i+1}:\\n{doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c987c",
   "metadata": {},
   "source": [
    "# RAG Pipeline with Hybrid Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a608795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "790d8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Prompt temlate\n",
    "template=\"\"\"\n",
    "        answer the user query  only on the given context{context}\n",
    "        question:{input}\n",
    "        \"\"\"\n",
    "prompt=PromptTemplate.from_template(\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8117b896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000022523CB1550>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000022523CB1FD0>, root_client=<openai.OpenAI object at 0x0000022522A22BA0>, root_async_client=<openai.AsyncOpenAI object at 0x0000022523CB1D30>, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the llm\n",
    "llm=init_chat_model(\"openai:gpt-3.5-turbo\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8a58910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002251FF59310>, search_kwargs={}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x000002251FF5B9D0>, k=3)], weights=[0.7, 0.3]), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\n        answer the user query  only on the given context{context}\\n        question:{input}\\n        ')\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000022523CB1550>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000022523CB1FD0>, root_client=<openai.OpenAI object at 0x0000022522A22BA0>, root_async_client=<openai.AsyncOpenAI object at 0x0000022523CB1D30>, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create document chain and rag chain\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)\n",
    "rag_chain=create_retrieval_chain(hybrid_retriever,document_chain)\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f78c3e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How can I build an application using LLMs?',\n",
       " 'context': [Document(id='0009ec1a-56fd-47f6-b3b7-7152c56b0557', metadata={}, page_content='LangChain helps build LLM applications.'),\n",
       "  Document(id='df32a673-c5f5-4f7d-876a-955450d2d350', metadata={}, page_content='Langchain can be used to develop agentic ai application.'),\n",
       "  Document(id='21475291-e59a-410f-9cc0-a39cfef438f6', metadata={}, page_content='Langchain has many types of retrievers.'),\n",
       "  Document(id='fd694038-ccd7-48b6-9259-2d64f852a89e', metadata={}, page_content='Pinecone is a vector database for semantic search.')],\n",
       " 'answer': \"One way to build an application using LLMs is by utilizing a platform like LangChain, which is designed to assist in creating Language Model applications. By leveraging LangChain's tools and resources, you can develop agentic AI applications that leverage the power of LLMs for various use cases. Additionally, LangChain offers various types of retrievers that can enhance the functionality and performance of your LLM-based application.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=rag_chain.invoke({\"input\":\"How can I build an application using LLMs?\"})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c41f9d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " answe: \n",
      "One way to build an application using LLMs is by utilizing a platform like LangChain, which is designed to assist in creating Language Model applications. By leveraging LangChain's tools and resources, you can develop agentic AI applications that leverage the power of LLMs for various use cases. Additionally, LangChain offers various types of retrievers that can enhance the functionality and performance of your LLM-based application.\n",
      "\n",
      " Source documentrs\n",
      "\n",
      "\n",
      "doc1:\n",
      "LangChain helps build LLM applications.\n",
      "\n",
      "doc2:\n",
      "Langchain can be used to develop agentic ai application.\n",
      "\n",
      "doc3:\n",
      "Langchain has many types of retrievers.\n",
      "\n",
      "doc4:\n",
      "Pinecone is a vector database for semantic search.\n"
     ]
    }
   ],
   "source": [
    "# output\n",
    "print(f\"\\n answe: \\n{results[\"answer\"]}\")\n",
    "print(\"\\n Source documentrs\\n\")\n",
    "for i,doc in enumerate(results['context']):\n",
    "    print(f\"\\ndoc{i+1}:\\n{doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b6a207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(3**2**0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d02bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
